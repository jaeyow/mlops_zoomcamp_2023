{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59a949c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MLOps Zoomcamp Module 1\")\n",
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfecb1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "catagorical = [\"PULocationID\", \"DOLocationID\"]\n",
    "\n",
    "def load_data_file(file):\n",
    "    '''\n",
    "    Created this function to use for both training and testing dataframes\n",
    "    '''\n",
    "    df = pd.read_parquet(file)\n",
    "    df[\"duration\"] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df[\"duration\"] = round(df.duration.dt.total_seconds() / 60, 2)\n",
    "\n",
    "    # pick up and drop off location need to be either categories or strings so that\n",
    "    # the DictVectorizer's one-hot encoding to work. It will not work if we keep them as \n",
    "    # numbers. \n",
    "    print(f\"Pick up locations: {len(df['PULocationID'].unique())}\")\n",
    "    print(f\"Drop off up locations: {len(df['DOLocationID'].unique())}\")\n",
    "    df[\"PULocationID\"] = df[\"PULocationID\"].astype(\"str\")\n",
    "    df[\"DOLocationID\"] = df[\"DOLocationID\"].astype(\"str\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f32b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = load_data_file(\"./data/yellow_tripdata_2022-01.parquet\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e908f051",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validate = load_data_file(\"./data/yellow_tripdata_2022-02.parquet\")\n",
    "df_validate.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0d2af4e",
   "metadata": {},
   "source": [
    "## Q1. Downloading the data\n",
    "\n",
    "We'll use [the same NYC taxi dataset](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page),\n",
    "but instead of \"**Green** Taxi Trip Records\", we'll use \"**Yellow** Taxi Trip Records\".\n",
    "\n",
    "Download the data for January and February 2022.\n",
    "\n",
    "Read the data for January. How many columns are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca429b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"January 2022 has {df_train.shape[1]} columns\")\n",
    "print(f\"Total number of rows: {df_train.shape[0]}\")\n",
    "df_train.dtypes\n",
    "\n",
    "print(f\"February 2022 has {df_validate.shape[1]} columns\")\n",
    "print(f\"Total number of rows: {df_validate.shape[0]}\")\n",
    "df_validate.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44ff5597",
   "metadata": {},
   "source": [
    "## Q2. Computing duration\n",
    "\n",
    "Now let's compute the `duration` variable. It should contain the duration of a ride in minutes. \n",
    "\n",
    "What's the standard deviation of the trips duration in January?\n",
    "\n",
    "* 41.45\n",
    "* **46.45**\n",
    "* 51.45\n",
    "* 56.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ecbdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The standard deviation of the trips duration in January 2022 is {round(df_train.duration.std(), 2)}\")\n",
    "df_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eaa8f451",
   "metadata": {},
   "source": [
    "## Q3. Dropping outliers\n",
    "\n",
    "Next, we need to check the distribution of the `duration` variable. There are some outliers. Let's remove them and keep only the records where the duration was between 1 and 60 minutes (inclusive).\n",
    "\n",
    "What fraction of the records left after you dropped the outliers?\n",
    "\n",
    "* 90%\n",
    "* 92%\n",
    "* 95%\n",
    "* **98%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ccd019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def remove_outliers(df):\n",
    "  '''\n",
    "  Here we decided that anything less that 1 minute and more than 1 hour are outliers\n",
    "  '''\n",
    "  lower_limit = 1\n",
    "  upper_limit = 60\n",
    "  num_rows = df.shape[0]\n",
    "  print(f\"Total number of rows: {num_rows}\")\n",
    "  outliers_lower_limit = (df[\"duration\"] < lower_limit)\n",
    "  outliers_upper_limit = (df[\"duration\"] > upper_limit)\n",
    "  len_lower = len(df['duration'][outliers_lower_limit])\n",
    "  len_upper = len(df['duration'][outliers_upper_limit])\n",
    "  print(f\"Dropping lower limit outliers: {len_lower}\")\n",
    "  print(f\"Dropping upper limit outliers: {len_upper}\")\n",
    "\n",
    "  # now we remove them... \n",
    "  df = df[~(outliers_lower_limit)]\n",
    "  df = df[~(outliers_upper_limit)]\n",
    "  df.reindex()\n",
    "  percent_left = ((num_rows - len_lower - len_upper)/num_rows * 100)\n",
    "  return percent_left, df\n",
    "\n",
    "\n",
    "sns.boxplot(df_train[\"duration\"])\n",
    "percent_left, df_train = remove_outliers(df_train)\n",
    "print(f\"Fraction of the records left after you dropped the outliers: {round(percent_left, 1)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651d5751",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, df_validate = remove_outliers(df_validate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e4da09",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df_train[\"duration\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0357e38c",
   "metadata": {},
   "source": [
    "## Q4. One-hot encoding\n",
    "\n",
    "Let's apply one-hot encoding to the pickup and dropoff location IDs. We'll use only these two features for our model. \n",
    "\n",
    "* Turn the dataframe into a list of dictionaries\n",
    "* Fit a dictionary vectorizer \n",
    "* Get a feature matrix from it\n",
    "\n",
    "What's the dimensionality of this matrix (number of columns)?\n",
    "\n",
    "* 2\n",
    "* 155\n",
    "* 345\n",
    "* **515**\n",
    "* 715"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5f05bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer # <== use this to create a sparse one hot encoding of categorical variables\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "df_train_convert = df_train[catagorical]\n",
    "train_dicts = df_train_convert.to_dict(orient='records')\n",
    "print(df_train_convert.dtypes)\n",
    "print(f\"train_dicts looks like: {train_dicts[:2][1]}\")\n",
    "\n",
    "dv = DictVectorizer()\n",
    "# now we convert the dictionary with one hot encoding for the categorical features\n",
    "# and no conversion for the other features\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "# how does an item in a sparse array look like? \n",
    "# print(X_train.toarray()[:1])\n",
    "print(f\"Shape of the sparse matrix (row, col): {X_train.shape}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a34e828",
   "metadata": {},
   "source": [
    "## Q5. Training a model\n",
    "\n",
    "Now let's use the feature matrix from the previous step to train a model. \n",
    "\n",
    "* Train a plain linear regression model with default parameters \n",
    "* Calculate the RMSE of the model on the training data\n",
    "\n",
    "What's the RMSE on train?\n",
    "\n",
    "* **6.99**\n",
    "* 11.99\n",
    "* 16.99\n",
    "* 21.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66698ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember the duration we calcluated from start and end time? We can use it\n",
    "# as a target of the prediction... \n",
    "y_train = df_train[\"duration\"].values\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train) # <=== Training time for all X_train values... \n",
    "\n",
    "print(f\"shape: {X_train.shape}\")\n",
    "y_pred = lr.predict(X_train)\n",
    "\n",
    "# then calculate the RMSE between X_train and y_pred values\n",
    "print(f\"RMSE: {round(mean_squared_error(y_train, y_pred, squared=False), 4)} mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2adba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(y_pred)\n",
    "sns.displot(y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f8023c4",
   "metadata": {},
   "source": [
    "## Q6. Evaluating the model\n",
    "\n",
    "Now let's apply this model to the validation dataset (February 2022). \n",
    "\n",
    "What's the RMSE on validation?\n",
    "\n",
    "* **7.79**\n",
    "* 12.79\n",
    "* 17.79\n",
    "* 22.79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0cf2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation = df_validate[catagorical]\n",
    "print(df_validation.dtypes)\n",
    "vali_dicts = df_validation.to_dict(orient='records')\n",
    "\n",
    "# now we convert the dictionary with one hot encoding for the categorical features\n",
    "# and no conversion for the other features\n",
    "X_vali = dv.transform(vali_dicts)\n",
    "\n",
    "print(f\"shape: {X_vali.shape}\")\n",
    "y_pred = lr.predict(X_vali)\n",
    "\n",
    "y_val = df_validate[\"duration\"].values\n",
    "print(f\"RMSE: {round(mean_squared_error(y_val, y_pred, squared=False), 4)} mins\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5134a72",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "The goal of this homework is to train a simple model for predicting the duration of a ride - similar to what we did in this module.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Submit the results\n",
    "\n",
    "* Submit your results here: https://forms.gle/uYTnWrcsubi2gdGV7\n",
    "* You can submit your solution multiple times. In this case, only the last submission will be used\n",
    "* If your answer doesn't match options exactly, select the closest one\n",
    "\n",
    "\n",
    "## Deadline\n",
    "\n",
    "The deadline for submitting is 23 May 2023 (Tuesday), 23:00 CEST (Berlin time). \n",
    "\n",
    "After that, the form will be closed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
